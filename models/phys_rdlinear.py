import torchimport torch.nn as nnfrom models.layers import SeriesDecompclass FreqRevIN(nn.Module):    # ... (保持原有的频域归一化代码不变) ...    def __init__(self, num_features: int, eps=1e-5, affine=True):        super().__init__()        self.num_features = num_features        self.eps = eps        self.affine = affine        if self.affine:            self.affine_weight = nn.Parameter(torch.ones(1, num_features, 1))            self.affine_bias = nn.Parameter(torch.zeros(1, num_features, 1))    def forward(self, x, mode='norm'):        if mode == 'norm':            self.mean = torch.mean(x, dim=1, keepdim=True).detach()            self.stdev = torch.sqrt(torch.var(x, dim=1, keepdim=True, unbiased=False) + self.eps).detach()            x = (x - self.mean) / self.stdev            if self.affine:                x = x * self.affine_weight + self.affine_bias            return x        return xclass PGFA(nn.Module):    # ... (保持 PGFA 代码不变，它是基于 Speed Hz 的硬物理约束) ...    def __init__(self, freq_dim: int, max_freq: float = 512.0, init_sigma: float = 2.0):        super().__init__()        self.sigma = nn.Parameter(torch.tensor(init_sigma))        self.alpha = nn.Parameter(torch.tensor(0.5))        self.register_buffer('freq_axis', torch.linspace(0, max_freq, freq_dim).view(1, -1, 1))    def forward(self, seasonal: torch.Tensor, speed_hz: torch.Tensor) -> torch.Tensor:        s = speed_hz.view(-1, 1, 1)        f = self.freq_axis        sig = torch.clamp(self.sigma, min=0.5, max=10.0)        denom = 2 * (sig ** 2)        # 基频 + 2/3次谐波 + 0.5次次谐波        mask = torch.exp(- (f - s) ** 2 / denom) + \               torch.exp(- (f - 2 * s) ** 2 / denom) + \               torch.exp(- (f - 3 * s) ** 2 / denom) + \               0.5 * torch.exp(- (f - 0.5 * s) ** 2 / denom)        return seasonal * (1 + self.alpha * mask)class AdaptiveFusion(nn.Module):    def __init__(self, hidden_dim):        super().__init__()        # 融合网络输入：[Speed_Hz, Current_RMS_Norm] -> 2维        # 输出：3个模态的注意力权重        self.weight_net = nn.Sequential(            nn.Linear(2, 16),            nn.ReLU(),            nn.Linear(16, 3)  # [w_vib, w_audio, w_current]        )        self.softmax = nn.Softmax(dim=1)    def forward(self, h_vib, h_aud, h_cur, speed, load_proxy):        # speed: [B, 1] (Hz)        # load_proxy: [B, 1] (Normalized Current RMS)        # 为了网络好训练，建议把 speed 也简单归一化一下输入给 MLP        # 假设最大转速 60Hz，除以 100 即可        cov = torch.cat([speed / 100.0, load_proxy], dim=1)  # [B, 2]        weights = self.softmax(self.weight_net(cov))        # 加权融合        fused = weights[:, 0:1] * h_vib + \                weights[:, 1:2] * h_aud + \                weights[:, 2:3] * h_cur        return fused, weightsclass PhysRDLinearCls(nn.Module):    def __init__(self, config, enable_pgfa=True, enable_mtl=False):        """        Args:            enable_pgfa: 是否开启物理引导频率对齐 (True)            enable_mtl:  是否开启多任务学习 (回归负载)                         现在我们将真正使用这个参数。        """        super().__init__()        self.enable_pgfa = enable_pgfa        # [修复 1] 真正激活 MTL 开关        self.enable_mtl = enable_mtl        # === 1. Vibration Stream (Micro: Low Freq) ===        self.revin_micro = FreqRevIN(config.FREQ_DIM, affine=False)        self.decomp = SeriesDecomp(kernel_size=25)        if self.enable_pgfa:            self.pgfa = PGFA(config.FREQ_DIM, max_freq=config.SAMPLE_RATE / 2, init_sigma=config.PGFA_SIGMA)        self.feat_vib = nn.Linear(config.FREQ_DIM, config.HIDDEN_DIM)        # === 2. Macro Stream (High Freq Supplement) ===        self.revin_macro = FreqRevIN(config.FREQ_DIM, affine=False)        self.feat_macro = nn.Linear(config.FREQ_DIM, config.HIDDEN_DIM)        self.vib_proj = nn.Linear(config.HIDDEN_DIM * 2, config.HIDDEN_DIM)        # === 3. Acoustic Stream ===        self.feat_aud = nn.Sequential(            nn.Linear(config.AUDIO_DIM, 64),            nn.ReLU(),            nn.Linear(64, config.HIDDEN_DIM)        )        # === 4. Current Spectrum Stream ===        self.feat_cur = nn.Sequential(            nn.Linear(config.CURRENT_DIM, 64),            nn.ReLU(),            nn.Linear(64, config.HIDDEN_DIM)        )        # === 5. Trend Branch (Physics-Driven Baseline) ===        # Speed(2) + Load(3) = 5        self.cov_expansion_dim = 5        self.trend_proj = nn.Sequential(            nn.Linear(self.cov_expansion_dim, config.HIDDEN_DIM),            nn.ReLU(),            nn.Dropout(0.3)        )        # === 6. Fusion & Classifier ===        self.fusion_layer = AdaptiveFusion(config.HIDDEN_DIM)        self.cls_head = nn.Sequential(            nn.BatchNorm1d(config.HIDDEN_DIM * 2),            nn.Linear(config.HIDDEN_DIM * 2, config.HIDDEN_DIM),            nn.ReLU(),            nn.Dropout(0.5),            nn.Linear(config.HIDDEN_DIM, config.NUM_CLASSES)        )        # [修复 2] 定义回归头 (Regression Head for MTL)        # 如果开启 MTL，我们需要一个层来预测负载        if self.enable_mtl:            # 输入是最终融合特征 (Trend + Seasonal) -> 输出 Load RMS (1维)            self.reg_head = nn.Linear(config.HIDDEN_DIM * 2, 1)    def forward(self, micro, macro, acoustic, current_spec, speed, load_proxy):        """        params:            speed: [B, 1] Speed in Hz            load_proxy: [B, 1] Normalized Current RMS (作为输入，也作为 MTL 的 Target)        """        # --- A. Vibration (Decomp + PGFA) ---        mic_norm = self.revin_micro(micro, 'norm')        sea_mic, _ = self.decomp(mic_norm)        if self.enable_pgfa:            sea_mic = self.pgfa(sea_mic, speed)        h_sea_mic = self.feat_vib(sea_mic.squeeze(-1))        # Macro        mac_norm = self.revin_macro(macro, 'norm')        h_mac = self.feat_macro(mac_norm.squeeze(-1))        h_vib = self.vib_proj(torch.cat([h_sea_mic, h_mac], dim=1))        # --- B. Other Modalities ---        h_aud = self.feat_aud(acoustic)        h_cur = self.feat_cur(current_spec)        # --- C. Adaptive Fusion ---        h_seasonal, weights = self.fusion_layer(h_vib, h_aud, h_cur, speed, load_proxy)        # --- D. Trend Branch (Physics-Guided Generator) ---        # 显式物理扩张        s_norm = speed / 100.0        feat_speed = torch.cat([s_norm, s_norm ** 2], dim=1)  # [B, 2]        i_norm = load_proxy        eps = 1e-5        feat_load = torch.cat([i_norm, i_norm ** 2, 1.0 / (torch.abs(i_norm) + eps)], dim=1)  # [B, 3]        trend_input = torch.cat([feat_speed, feat_load], dim=1)  # [B, 5]        h_trend = self.trend_proj(trend_input)        # --- E. Final Output ---        out_feat = torch.cat([h_trend, h_seasonal], dim=1)        logits = self.cls_head(out_feat)        # [修复 3] 计算回归输出 (MTL Output)        pred_load = None        if self.enable_mtl:            # 预测负载值，Trainer 会拿着它去和 load_proxy 计算 MSE Loss            pred_load = self.reg_head(out_feat)        # 返回 logits 和 pred_load (如果是 None，Trainer 会自动跳过回归 Loss)        return logits, pred_load