import torchimport torch.nn as nnfrom models.layers import SeriesDecompclass FreqRevIN(nn.Module):    # ... (保持原有的频域归一化代码不变) ...    def __init__(self, num_features: int, eps=1e-5, affine=True):        super().__init__()        self.num_features = num_features        self.eps = eps        self.affine = affine        if self.affine:            self.affine_weight = nn.Parameter(torch.ones(1, num_features, 1))            self.affine_bias = nn.Parameter(torch.zeros(1, num_features, 1))    def forward(self, x, mode='norm'):        if mode == 'norm':            self.mean = torch.mean(x, dim=1, keepdim=True).detach()            self.stdev = torch.sqrt(torch.var(x, dim=1, keepdim=True, unbiased=False) + self.eps).detach()            x = (x - self.mean) / self.stdev            if self.affine:                x = x * self.affine_weight + self.affine_bias            return x        return xclass PGFA(nn.Module):    # ... (保持 PGFA 代码不变，它是基于 Speed Hz 的硬物理约束) ...    def __init__(self, freq_dim: int, max_freq: float = 512.0, init_sigma: float = 2.0):        super().__init__()        self.sigma = nn.Parameter(torch.tensor(init_sigma))        self.alpha = nn.Parameter(torch.tensor(0.5))        self.register_buffer('freq_axis', torch.linspace(0, max_freq, freq_dim).view(1, -1, 1))    def forward(self, seasonal: torch.Tensor, speed_hz: torch.Tensor) -> torch.Tensor:        s = speed_hz.view(-1, 1, 1)        f = self.freq_axis        sig = torch.clamp(self.sigma, min=0.5, max=10.0)        denom = 2 * (sig ** 2)        # 基频 + 2/3次谐波 + 0.5次次谐波        mask = torch.exp(- (f - s) ** 2 / denom) + \               torch.exp(- (f - 2 * s) ** 2 / denom) + \               torch.exp(- (f - 3 * s) ** 2 / denom) + \               0.5 * torch.exp(- (f - 0.5 * s) ** 2 / denom)        return seasonal * (1 + self.alpha * mask)class AdaptiveFusion(nn.Module):    def __init__(self, hidden_dim):        super().__init__()        # 融合网络输入：[Speed_Hz, Current_RMS_Norm] -> 2维        # 输出：3个模态的注意力权重        self.weight_net = nn.Sequential(            nn.Linear(2, 16),            nn.ReLU(),            nn.Linear(16, 3)  # [w_vib, w_audio, w_current]        )        self.softmax = nn.Softmax(dim=1)    def forward(self, h_vib, h_aud, h_cur, speed, load_proxy):        # speed: [B, 1] (Hz)        # load_proxy: [B, 1] (Normalized Current RMS)        # 为了网络好训练，建议把 speed 也简单归一化一下输入给 MLP        # 假设最大转速 60Hz，除以 100 即可        cov = torch.cat([speed / 100.0, load_proxy], dim=1)  # [B, 2]        weights = self.softmax(self.weight_net(cov))        # 加权融合        fused = weights[:, 0:1] * h_vib + \                weights[:, 1:2] * h_aud + \                weights[:, 2:3] * h_cur        return fused, weightsclass PhysRDLinearCls(nn.Module):    def __init__(self, config, enable_pgfa=True, enable_mtl=False):        super().__init__()        self.enable_pgfa = enable_pgfa        # === 1. Vibration Stream (Micro: Low Freq) ===        self.revin_micro = FreqRevIN(config.FREQ_DIM, affine=False)        self.decomp = SeriesDecomp(kernel_size=25)        if self.enable_pgfa:            # 这里的 max_freq 和 sigma 需确保 config 里有定义            self.pgfa = PGFA(config.FREQ_DIM, max_freq=config.SAMPLE_RATE / 2, init_sigma=config.PGFA_SIGMA)        self.feat_vib = nn.Linear(config.FREQ_DIM, config.HIDDEN_DIM)        # === 2. Macro Stream (High Freq Supplement) ===        self.revin_macro = FreqRevIN(config.FREQ_DIM, affine=False)        self.feat_macro = nn.Linear(config.FREQ_DIM, config.HIDDEN_DIM)        self.vib_proj = nn.Linear(config.HIDDEN_DIM * 2, config.HIDDEN_DIM)        # === 3. Acoustic Stream ===        self.feat_aud = nn.Sequential(            nn.Linear(config.AUDIO_DIM, 64),            nn.ReLU(),            nn.Linear(64, config.HIDDEN_DIM)        )        # === 4. Current Spectrum Stream ===        self.feat_cur = nn.Sequential(            nn.Linear(config.CURRENT_DIM, 64),            nn.ReLU(),            nn.Linear(64, config.HIDDEN_DIM)        )        # === 5. Trend Branch (Physics-Driven Baseline) ===        # [修改点 1] 物理约束改造        # 旧逻辑: 输入是 Signal_Trend(512) + Covariates(2) -> 允许"作弊"        # 新逻辑: 输入仅为 Covariates (Speed_Exp + Load_Exp) -> 强迫学习物理映射        # 维度计算: Speed(2: S, S^2) + Load(3: I, I^2, 1/I) = 5        self.cov_expansion_dim = 5        self.trend_proj = nn.Sequential(            nn.Linear(self.cov_expansion_dim, config.HIDDEN_DIM),  # 输入维度变小了，更专注            nn.ReLU(),            nn.Dropout(0.3)  # 保持 Dropout 防止过拟合        )        # === 6. Fusion & Classifier ===        self.fusion_layer = AdaptiveFusion(config.HIDDEN_DIM)        self.cls_head = nn.Sequential(            nn.BatchNorm1d(config.HIDDEN_DIM * 2),            nn.Linear(config.HIDDEN_DIM * 2, config.HIDDEN_DIM),            nn.ReLU(),            nn.Dropout(0.5),            nn.Linear(config.HIDDEN_DIM, config.NUM_CLASSES)        )    def forward(self, micro, macro, acoustic, current_spec, speed, load_proxy):        """        params:            speed: [B, 1] Speed in Hz            load_proxy: [B, 1] Normalized Current RMS        """        # --- A. Vibration (Decomp + PGFA) ---        mic_norm = self.revin_micro(micro, 'norm')        # Trend component is extracted but NOT used in Trend Branch (Physics Constraint)        sea_mic, _ = self.decomp(mic_norm)        if self.enable_pgfa:            sea_mic = self.pgfa(sea_mic, speed)        h_sea_mic = self.feat_vib(sea_mic.squeeze(-1))        # Macro        mac_norm = self.revin_macro(macro, 'norm')        h_mac = self.feat_macro(mac_norm.squeeze(-1))        h_vib = self.vib_proj(torch.cat([h_sea_mic, h_mac], dim=1))        # --- B. Other Modalities ---        h_aud = self.feat_aud(acoustic)        h_cur = self.feat_cur(current_spec)        # --- C. Adaptive Fusion ---        h_seasonal, weights = self.fusion_layer(h_vib, h_aud, h_cur, speed, load_proxy)        # --- D. Trend Branch (Physics-Guided Generator) ---        # [修改点 2] 显式物理扩张 (Explicit Feature Expansion)        # 1. 转速扩张: [S, S^2] (归一化防止数值爆炸)        s_norm = speed / 100.0        feat_speed = torch.cat([s_norm, s_norm ** 2], dim=1)  # [B, 2]        # 2. 负载扩张: [I, I^2, 1/(I+eps)]        # 负载与能量呈非线性关系 (U型或抛物线)，I^2 拟合功率，1/I 拟合低载时的非线性摩擦        i_norm = load_proxy  # 假设 load_proxy 已经是归一化后的 RMS        eps = 1e-5        feat_load = torch.cat([i_norm, i_norm ** 2, 1.0 / (torch.abs(i_norm) + eps)], dim=1)  # [B, 3]        # 3. 拼接协变量        trend_input = torch.cat([feat_speed, feat_load], dim=1)  # [B, 5]        # 4. 生成基线嵌入 (Baseline Embedding)        # 这里的 h_trend 代表"在该工况下，理论上正常的能量基线特征是什么"        h_trend = self.trend_proj(trend_input)        # --- E. Final Output ---        # Classifier 现在的逻辑是：        # 对比 (h_seasonal: 实际的高频信号) 和 (h_trend: 理论的基线信号)        # 如果 h_seasonal 里的能量远超 h_trend 预测的基线 -> 故障        out_feat = torch.cat([h_trend, h_seasonal], dim=1)        logits = self.cls_head(out_feat)        return logits, None