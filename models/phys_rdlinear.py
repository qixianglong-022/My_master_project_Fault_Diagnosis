import torchimport torch.nn as nnimport torch.nn.functional as Ffrom typing import Tupleclass RevIN(nn.Module):    """Reversible Instance Normalization to handle domain shifts."""    def __init__(self, num_features: int, eps: float = 1e-5, affine: bool = True):        super().__init__()        self.num_features = num_features        self.eps = eps        self.affine = affine        if self.affine:            self.affine_weight = nn.Parameter(torch.ones(num_features))            self.affine_bias = nn.Parameter(torch.zeros(num_features))    def forward(self, x: torch.Tensor, mode: str) -> torch.Tensor:        if mode == 'norm':            self.mean = torch.mean(x, dim=1, keepdim=True).detach()            self.stdev = torch.sqrt(torch.var(x, dim=1, keepdim=True, unbiased=False) + self.eps).detach()            x = (x - self.mean) / self.stdev            if self.affine:                x = x * self.affine_weight + self.affine_bias            return x        elif mode == 'denorm':            if self.affine:                x = (x - self.affine_bias) / (self.affine_weight + self.eps * self.affine_weight)            x = x * self.stdev + self.mean            return x        return xclass SeriesDecomp(nn.Module):    """Frequency Domain Decomposition: Trend (Low Freq/Envelope) + Seasonal (High Freq/Peaks)."""    def __init__(self, kernel_size: int = 25):        super().__init__()        self.avg = nn.AvgPool1d(kernel_size=kernel_size, stride=1, padding=kernel_size // 2, count_include_pad=False)    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:        # x: [B, L, 1]        x_t = x.permute(0, 2, 1)  # [B, 1, L]        trend = self.avg(x_t).permute(0, 2, 1)  # [B, L, 1]        seasonal = x - trend        return seasonal, trendclass PGFA(nn.Module):    """    Physics-Guided Frequency Attention.    Generates a dynamic Gaussian Mask based on real-time speed.    """    def __init__(self, freq_dim: int, sigma: float = 10.0):        super().__init__()        self.freq_dim = freq_dim        self.sigma = sigma        # Learnable intensity of the physics injection        self.alpha = nn.Parameter(torch.tensor(0.5))        # Register frequency axis buffer (0 to 500Hz roughly for micro-stream)        # Assuming sample_rate/2 mapping. Normalized range 0-1 or Hz depends on input speed unit.        # Here we assume speed_hz is actual Hz, so we map indices to Hz.        # For simplicity in this demo, we assume indices 0..L map linearly.        self.register_buffer('freq_axis', torch.linspace(0, 500, freq_dim))    def forward(self, seasonal: torch.Tensor, speed_hz: torch.Tensor) -> torch.Tensor:        """        Args:            seasonal: [B, L, 1]            speed_hz: [B, 1]        Returns:            Enhanced seasonal features        """        # Vectorized Gaussian Mask Generation        # Mask shape: [B, L, 1]        # We focus on 1x and 2x harmonics        f = self.freq_axis.view(1, -1, 1)  # [1, L, 1]        s = speed_hz.view(-1, 1, 1)  # [B, 1, 1]        mask = torch.exp(-0.5 * (f - s) ** 2 / self.sigma) + \               torch.exp(-0.5 * (f - 2 * s) ** 2 / self.sigma)        # Physics Injection via Hadamard Product (Residual connection)        # Seasonal_Guided = Seasonal * (1 + alpha * Mask)        return seasonal * (1 + self.alpha * mask)class PhysRDLinearCls(nn.Module):    """    Chapter 4 Core Model: Physics-Guided Decomposed Linear Model.    """    def __init__(self, config):        super().__init__()        self.config = config        # 1. Frequency-domain RevIN        self.revin = RevIN(num_features=1)        # 2. Decomposition        self.decomp = SeriesDecomp(kernel_size=25)        # 3. Physics Attention        self.pgfa = PGFA(freq_dim=config.FREQ_DIM, sigma=config.PGFA_SIGMA)        # 4. Feature Extractors        self.linear_trend = nn.Linear(config.FREQ_DIM, config.HIDDEN_DIM)        self.linear_seasonal = nn.Linear(config.FREQ_DIM, config.HIDDEN_DIM)        # 5. Heads        # Task A: Virtual Load Sensor (Condition Decoupling)        self.load_head = nn.Sequential(            nn.Linear(config.HIDDEN_DIM, 64),            nn.ReLU(),            nn.Linear(64, 1)  # Outputs normalized load        )        # Task B: Fault Diagnosis (Main Task)        self.cls_head = nn.Sequential(            nn.Linear(config.HIDDEN_DIM * 2, config.HIDDEN_DIM),            nn.ReLU(),            nn.Dropout(0.2),            nn.Linear(config.HIDDEN_DIM, config.NUM_CLASSES)        )    def forward(self, x: torch.Tensor, speed_hz: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:        # x: [B, L, 1]        # A. RevIN Normalization (Handling Amplitude Shift)        x = self.revin(x, 'norm')        # B. Decomposition        seasonal, trend = self.decomp(x)        # C. Physics-Guided Enhancement (PGFA on Seasonal)        seasonal_guided = self.pgfa(seasonal, speed_hz)        # D. Feature Mapping        # Flatten: [B, L, 1] -> [B, L]        t_feat = self.linear_trend(trend.squeeze(-1))        s_feat = self.linear_seasonal(seasonal_guided.squeeze(-1))        # E. Multi-Task Outputs        # 1. Virtual Load Prediction (from Trend only)        pred_load = self.load_head(t_feat)        # 2. Fault Classification (Fusion of Trend + Guided Seasonal)        fusion = torch.cat([t_feat, s_feat], dim=1)        logits = self.cls_head(fusion)        return logits, pred_load