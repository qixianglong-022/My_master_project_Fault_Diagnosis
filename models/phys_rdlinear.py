import torchimport torch.nn as nnfrom typing import Tupleclass RevIN(nn.Module):    def __init__(self, num_features: int, eps: float = 1e-5, affine: bool = True):        super().__init__()        self.num_features = num_features        self.eps = eps        self.affine = affine        if self.affine:            self.affine_weight = nn.Parameter(torch.ones(num_features))            self.affine_bias = nn.Parameter(torch.zeros(num_features))    def forward(self, x: torch.Tensor, mode: str) -> torch.Tensor:        if mode == 'norm':            self.mean = torch.mean(x, dim=1, keepdim=True).detach()            self.stdev = torch.sqrt(torch.var(x, dim=1, keepdim=True, unbiased=False) + self.eps).detach()            x = (x - self.mean) / self.stdev            if self.affine: x = x * self.affine_weight + self.affine_bias            return x        return xclass SeriesDecomp(nn.Module):    def __init__(self, kernel_size: int = 25):        super().__init__()        self.avg = nn.AvgPool1d(kernel_size=kernel_size, stride=1, padding=kernel_size // 2, count_include_pad=False)    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:        x_t = x.permute(0, 2, 1)        trend = self.avg(x_t).permute(0, 2, 1)        seasonal = x - trend        return seasonal, trendclass PGFA(nn.Module):    def __init__(self, freq_dim: int, sigma: float = 3.0):        super().__init__()        self.sigma = sigma        self.alpha = nn.Parameter(torch.tensor(0.5))        self.register_buffer('freq_axis', torch.linspace(0, 500, freq_dim))    def forward(self, seasonal: torch.Tensor, speed_hz: torch.Tensor) -> torch.Tensor:        f = self.freq_axis.view(1, -1, 1)        s = speed_hz.view(-1, 1, 1)        mask = torch.exp(-0.5 * (f - s) ** 2 / self.sigma) + \               torch.exp(-0.5 * (f - 2 * s) ** 2 / self.sigma) + \               torch.exp(-0.5 * (f - 3 * s) ** 2 / self.sigma)        return seasonal * (1 + self.alpha * mask)class PhysRDLinearCls(nn.Module):    """    [RQ4 升级版] 支持声纹融合    """    def __init__(self, config, enable_pgfa=True, enable_mtl=True, enable_acoustic=False):        super().__init__()        self.enable_pgfa = enable_pgfa        self.enable_mtl = enable_mtl        self.enable_acoustic = enable_acoustic  # [New] 声纹开关        # --- Stream 1: Micro ---        self.revin_micro = RevIN(num_features=1)        self.decomp = SeriesDecomp(kernel_size=25)        if self.enable_pgfa:            self.pgfa = PGFA(freq_dim=config.FREQ_DIM, sigma=config.PGFA_SIGMA)        self.lin_trend = nn.Linear(config.FREQ_DIM, config.HIDDEN_DIM)        self.lin_sea = nn.Linear(config.FREQ_DIM, config.HIDDEN_DIM)        # --- Stream 2: Macro ---        self.revin_macro = RevIN(num_features=1)        self.lin_macro = nn.Linear(config.FREQ_DIM, config.HIDDEN_DIM)        # --- Stream 3: Acoustic [New] ---        if self.enable_acoustic:            # 输入 26 维 MFCC，映射到 Hidden Dim            self.acoustic_head = nn.Linear(26, config.HIDDEN_DIM)        # --- Heads ---        if self.enable_mtl:            self.load_head = nn.Sequential(nn.Linear(config.HIDDEN_DIM, 64), nn.ReLU(), nn.Linear(64, 1))        # Task B: Classification (根据是否开启声纹调整输入维度)        # Vib Only: 3 * Hidden        # Fusion:   4 * Hidden        fusion_dim = config.HIDDEN_DIM * 4 if self.enable_acoustic else config.HIDDEN_DIM * 3        self.cls_head = nn.Sequential(            nn.Linear(fusion_dim, config.HIDDEN_DIM),            nn.ReLU(),            nn.Dropout(0.2),            nn.Linear(config.HIDDEN_DIM, config.NUM_CLASSES)        )    def forward(self, x_micro, x_macro, x_acoustic, speed_hz):        # 1. Micro        x_micro = self.revin_micro(x_micro, 'norm')        sea, trend = self.decomp(x_micro)        sea_guided = self.pgfa(sea, speed_hz) if self.enable_pgfa else sea        f_trend = self.lin_trend(trend.squeeze(-1))        f_sea = self.lin_sea(sea_guided.squeeze(-1))        # 2. Macro        x_macro = self.revin_macro(x_macro, 'norm')        f_macro = self.lin_macro(x_macro.squeeze(-1))        # 3. Acoustic (如果开启)        feats = [f_trend, f_sea, f_macro]        if self.enable_acoustic:            # x_acoustic: [B, 26]            f_acoustic = self.acoustic_head(x_acoustic)            feats.append(f_acoustic)        # Fusion & Output        fusion = torch.cat(feats, dim=1)        logits = self.cls_head(fusion)        pred_load = None        if self.enable_mtl:            pred_load = self.load_head(f_trend)        return logits, pred_load